name: Test

permissions:
  contents: read
  packages: read
  id-token: write
  pull-requests: write
  checks: write

on:
  workflow_call:
    inputs:
      ref:
        type: string
        description: "The branch, tag, or SHA to run on"
        required: false
        default: ""
      debug:
        type: boolean
        description: "Run with debugging enabled"
        required: false
        default: false
      large:
        type: boolean
        description: "Run large tests"
        required: false
        default: false
      kubernetes:
        type: boolean
        description: "Run kubernetes tests"
        required: false
        default: true
      parallelism:
        type: number
        description: "Parallelism for running tests"
        required: false
        default: 2
      parallelism_gpu:
        type: number
        description: "Parallelism for running GPU tests"
        required: false
        default: 2
      runner:
        type: string
        description: "Runner machine for CPU tests"
        required: false
        default: 2cpu
      runner_gpu:
        type: string
        description: "Runner machine for GPU tests"
        required: false
        default: 4cpu-1gpu
      post_summary_slack:
        type: string
        description: "Webhook URL for posting summary to Slack"
        required: false
        default: ""

env:
  CEDANA_URL: ${{ vars.CEDANA_URL }}
  CEDANA_AUTH_TOKEN: ${{ secrets.CEDANA_AUTH_TOKEN }}
  CEDANA_LOG_LEVEL: debug
  AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
  AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
  AWS_REGION: ${{ vars.AWS_REGION }}
  FORMATTER: junit
  RETRIES: 1
  DEBUG: ${{ vars.DEBUG_REGRESSION }}

jobs:
  unit:
    name: Unit
    runs-on: runs-on=${{github.run_id}}/runner=1cpu-${{ matrix.arch }}/extras=s3-cache
    strategy:
      fail-fast: false
      matrix:
        arch:
          - amd64
          - arm64
    container:
      image: golang:1.25rc3-bullseye
      credentials:
        username: ${{ vars.DOCKER_USERNAME }}
        password: ${{ secrets.DOCKER_TOKEN }}
    steps:
      - uses: runs-on/action@v1
      - uses: actions/checkout@v4
        with:
          repository: cedana/cedana # required for workflows reusing this workflow
          ref: ${{ inputs.ref }}
          fetch-depth: 0
          fetch-tags: true

      - name: Download binary
        uses: actions/download-artifact@v4
        with:
          name: cedana-${{ matrix.arch }}

      - name: Download plugins
        uses: actions/download-artifact@v4
        with:
          path: .
          pattern: plugin-${{ matrix.arch }}*
          merge-multiple: true

      - name: Make executable
        run: |
          chmod +x ./cedana
          chmod +x ./libcedana-*.so

      - name: Setup debugging session
        uses: mxschmitt/action-tmate@v3
        if: inputs.debug
        with:
          limit-access-to-actor: true

      - name: Run unit tests
        run: make test-unit

  script:
    name: Script
    runs-on: runs-on=${{github.run_id}}/runner=1cpu-${{ matrix.arch }}/extras=s3-cache
    strategy:
      fail-fast: false
      matrix:
        name:
          - k8s-setup-host
          # - slurm-setup-host
        arch:
          - amd64
          - arm64
    steps:
      - uses: runs-on/action@v1
      - uses: actions/checkout@v4
        with:
          repository: cedana/cedana # required for workflows reusing this workflow
          ref: ${{ inputs.ref }}
          fetch-depth: 0
          fetch-tags: true

      - uses: actions/download-artifact@v4
        with:
          name: cedana-${{ matrix.arch }}

      - name: Run k8s setup host
        env:
          CEDANA_PLUGINS_BUILDS: local # change to alpha to test plugin downloads
        run: |
          sudo chmod +x ./cedana
          sudo cp ./cedana /usr/local/bin/
          sudo mkdir -p /cedana/scripts/host
          sudo cp -r ./scripts/host/* /cedana/scripts/host
          sudo \
            ENV="CI" \
            CEDANA_URL="${CEDANA_URL}" \
            CEDANA_AUTH_TOKEN="${CEDANA_AUTH_TOKEN}" \
            CEDANA_LOG_LEVEL="${CEDANA_LOG_LEVEL}" \
            CEDANA_PLUGINS_BUILDS="${CEDANA_PLUGINS_BUILDS}" \
            /cedana/scripts/host/${{ matrix.name }}.sh

  basic:
    name: Basic
    runs-on: runs-on=${{github.run_id}}/runner=${{ inputs.runner }}-${{ matrix.arch }}/extras=s3-cache
    timeout-minutes: 30
    strategy:
      fail-fast: false
      matrix:
        arch:
          - amd64
          - arm64
    container:
      image: cedana/cedana-test:latest
      credentials:
        username: ${{ vars.DOCKER_USERNAME }}
        password: ${{ secrets.DOCKER_TOKEN }}
      options: --privileged --init --cgroupns=host
    steps:
      - uses: runs-on/action@v1
      - uses: actions/checkout@v4
        with:
          repository: cedana/cedana # required for workflows reusing this workflow
          ref: ${{ inputs.ref }}
          fetch-depth: 0
          fetch-tags: true

      - name: Download binary
        uses: actions/download-artifact@v4
        with:
          name: cedana-${{ matrix.arch }}

      - name: Download CRIU
        uses: actions/download-artifact@v4
        with:
          name: criu-${{ matrix.arch }}

      - name: Make executable
        run: |
          chmod +x ./cedana*
          chmod +x ./criu
          echo "$PWD" >> $GITHUB_PATH

      - name: Install
        run: |
          make install
          sudo -E cedana plugin install criu

      - name: Mark git dir as safe
        run: git config --global --add safe.directory "$(pwd)"

      - name: Setup debugging session
        uses: mxschmitt/action-tmate@v3
        if: inputs.debug
        with:
          limit-access-to-actor: true

      - name: Run regression tests
        env:
          LARGE: ${{ inputs.large }}
          PARALLELISM: ${{ inputs.parallelism }}
        run: |
          if [ "$LARGE" = "true" ]; then
            make test-regression TAGS=base PARALLELISM=$PARALLELISM RETRIES=$RETRIES DEBUG=$DEBUG FORMATTER=$FORMATTER
          else
            make test-regression TAGS=base,!large PARALLELISM=$PARALLELISM RETRIES=$RETRIES DEBUG=$DEBUG FORMATTER=$FORMATTER
          fi

      - name: Setup node
        if: always()
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: Generate report (isolated)
        if: always()
        run: |
          npx junit-to-ctrf "/tmp/report-isolated.xml" -t bats -o /tmp/report-isolated.json -e \
            appName="cedana" appVersion="$(git describe --tags --always)" \
            buildName="${{ github.head_ref || github.ref_name }}" buildNumber="${{ github.run_number }}" \
            buildUrl="${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}" \
            repositoryName="${{ github.repository }}" repositoryUrl="${{ github.server_url }}/${{ github.repository }}" \
            commit="${{ github.sha }}" branchName="${{ github.head_ref || github.ref_name }}" \
            osPlatform="$(uname -s) (${{ matrix.arch }})" osRelease="$(uname -r)" \
            testEnvironment="cedana/cedana-test" reportName="Basic (${{ matrix.arch }})"

      - name: Generate report (persistent)
        if: always()
        run: |
          npx junit-to-ctrf "/tmp/report-persistent.xml" -t bats -o /tmp/report-persistent.json -e \
            appName="cedana" appVersion="$(git describe --tags --always)" \
            buildName="${{ github.head_ref || github.ref_name }}" buildNumber="${{ github.run_number }}" \
            buildUrl="${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}" \
            repositoryName="${{ github.repository }}" repositoryUrl="${{ github.server_url }}/${{ github.repository }}" \
            commit="${{ github.sha }}" branchName="${{ github.head_ref || github.ref_name }}" \
            osPlatform="$(uname -s) (${{ matrix.arch }})" osRelease="$(uname -r)" \
            testEnvironment="cedana/cedana-test" reportName="Basic (${{ matrix.arch }})"

      - name: Upload report
        if: always()
        id: upload-report
        uses: actions/upload-artifact@v4
        with:
          name: test-report-${{ matrix.arch }}
          path: |
            /tmp/report*.json

  plugin:
    name: Plugin
    runs-on: runs-on=${{github.run_id}}/runner=${{ inputs.runner }}-${{ matrix.arch }}/tag=${{ matrix.plugin }}/extras=s3-cache
    timeout-minutes: 30
    strategy:
      fail-fast: false
      matrix:
        plugin:
          - runc
          - containerd
          - crio
          - storage/cedana
          - storage/s3
          - storage/gcs
        arch:
          - amd64
          - arm64
    container:
      image: cedana/cedana-test:latest
      credentials:
        username: ${{ vars.DOCKER_USERNAME }}
        password: ${{ secrets.DOCKER_TOKEN }}
      options: --privileged --init --cgroupns=host
    steps:
      - uses: runs-on/action@v1
      - uses: actions/checkout@v4
        with:
          repository: cedana/cedana # required for workflows reusing this workflow
          ref: ${{ inputs.ref }}
          fetch-depth: 0
          fetch-tags: true

      - name: Download binary
        uses: actions/download-artifact@v4
        with:
          name: cedana-${{ matrix.arch }}

      - name: Download plugins
        uses: actions/download-artifact@v4
        with:
          path: .
          pattern: plugin-${{ matrix.arch }}*
          merge-multiple: true

      - name: Download CRIU
        uses: actions/download-artifact@v4
        with:
          name: criu-${{ matrix.arch }}

      - name: Download containerd runtime
        if: matrix.plugin == 'containerd'
        uses: actions/download-artifact@v4
        with:
          path: .
          pattern: containerd-runtime-${{ matrix.arch }}-*
          merge-multiple: true

      - name: Make executable
        run: |
          chmod +x ./cedana*
          chmod +x ./criu
          echo "$PWD" >> $GITHUB_PATH

      - name: Install
        run: |
          make install
          sudo -E cedana plugin install ${{ matrix.plugin }} criu runc storage/cedana storage/s3 storage/gcs
          if [ "${{ matrix.plugin }}" = "containerd" ]; then
            sudo -E cedana plugin install containerd/runtime-runc
          fi

      - name: Mark git dir as safe
        run: git config --global --add safe.directory "$(pwd)"

      - name: Setup debugging session
        uses: mxschmitt/action-tmate@v3
        if: inputs.debug
        with:
          limit-access-to-actor: true

      - name: Run regression tests
        env:
          LARGE: ${{ inputs.large }}
          PARALLELISM: ${{ inputs.parallelism }}
          PLUGIN: ${{ matrix.plugin }}
        run: |
          # replace slash in plugin with colon so that the tag is namespaced correctly
          # e.g. storage/cedana -> storage:cedana
          PLUGIN=$(echo $PLUGIN | sed 's/\//:/g')
          if [ "$LARGE" = "true" ]; then
            make test-regression TAGS=!gpu,!streamer,$PLUGIN PARALLELISM=$PARALLELISM RETRIES=$RETRIES DEBUG=$DEBUG FORMATTER=$FORMATTER
          else
            make test-regression TAGS=!gpu,!streamer,$PLUGIN,!large PARALLELISM=$PARALLELISM RETRIES=$RETRIES DEBUG=$DEBUG FORMATTER=$FORMATTER
          fi

      - name: Set plugin name
        if: always()
        env:
          PLUGIN: ${{ matrix.plugin }}
        run: |
          PLUGIN=$(echo $PLUGIN | sed 's/\//-/g')
          echo "PLUGIN=$PLUGIN" >> $GITHUB_ENV

      - name: Setup node
        if: always()
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: Generate report (isolated)
        if: always()
        run: |
          npx junit-to-ctrf "/tmp/report-isolated.xml" -t bats -o /tmp/report-isolated.json -e \
            appName="cedana" appVersion="$(git describe --tags --always)" \
            buildName="${{ github.head_ref || github.ref_name }}" buildNumber="${{ github.run_number }}" \
            buildUrl="${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}" \
            repositoryName="${{ github.repository }}" repositoryUrl="${{ github.server_url }}/${{ github.repository }}" \
            commit="${{ github.sha }}" branchName="${{ github.head_ref || github.ref_name }}" \
            osPlatform="$(uname -s) (${{ matrix.arch }})" osRelease="$(uname -r)" \
            testEnvironment="cedana/cedana-test" reportName="${{ matrix.plugin }} (${{ matrix.arch }})"

      - name: Generate report (persistent)
        if: always()
        run: |
          npx junit-to-ctrf "/tmp/report-persistent.xml" -t bats -o /tmp/report-persistent.json -e \
            appName="cedana" appVersion="$(git describe --tags --always)" \
            buildName="${{ github.head_ref || github.ref_name }}" buildNumber="${{ github.run_number }}" \
            buildUrl="${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}" \
            repositoryName="${{ github.repository }}" repositoryUrl="${{ github.server_url }}/${{ github.repository }}" \
            commit="${{ github.sha }}" branchName="${{ github.head_ref || github.ref_name }}" \
            osPlatform="$(uname -s) (${{ matrix.arch }})" osRelease="$(uname -r)" \
            testEnvironment="cedana/cedana-test" reportName="${{ matrix.plugin }} (${{ matrix.arch }})"

      - name: Upload report
        if: always()
        id: upload-report
        uses: actions/upload-artifact@v4
        with:
          name: test-report-${{ matrix.arch }}-${{ env.PLUGIN }}
          path: |
            /tmp/report*.json

  streamer:
    name: Streamer
    uses: ./.github/workflows/test_streamer.yml
    secrets: inherit
    with:
      ref: ${{ inputs.ref }}
      debug: ${{ inputs.debug }}
      large: ${{ inputs.large }}
      parallelism: ${{ inputs.parallelism }}
      parallelism_gpu: ${{ inputs.parallelism_gpu }}
      runner: ${{ inputs.runner }}
      runner_gpu: ${{ inputs.runner_gpu }}
      post_summary: false # Will post consolidated summary instead

  gpu:
    name: GPU
    uses: ./.github/workflows/test_gpu.yml
    secrets: inherit
    with:
      ref: ${{ inputs.ref }}
      debug: ${{ inputs.debug }}
      large: ${{ inputs.large }}
      parallelism: ${{ inputs.parallelism_gpu }}
      runner: ${{ inputs.runner_gpu }}
      post_summary: false # Will post consolidated summary instead

  # XXX: Below kubernetes tests are split into separate workflows, instead of using matrix,
  # because of Github Actions issue of using concurrency group together with matrix jobs
  # within the same workflow file.
  # https://github.com/orgs/community/discussions/26774

  k3s:
    name: Kubernetes
    uses: ./.github/workflows/test_k8s.yml
    if: ${{ inputs.kubernetes }}
    secrets: inherit
    with:
      ref: ${{ inputs.ref }}
      debug: ${{ inputs.debug }}
      platform: K3s
      large: false # K3s is only for small tests
      runner: ${{ inputs.runner }}
      runner_gpu: ${{ inputs.runner_gpu }}
      parallelism: ${{ inputs.parallelism }}
      post_summary: false # Will post consolidated summary instead

  eks:
    name: Kubernetes
    uses: ./.github/workflows/test_k8s.yml
    if: ${{ inputs.kubernetes }}
    secrets: inherit
    concurrency: test-k8s-eks # Since the cluster is reused
    with:
      ref: ${{ inputs.ref }}
      debug: ${{ inputs.debug }}
      platform: EKS
      runner: ${{ inputs.runner }}
      large: ${{ inputs.large }}
      runner_gpu: ${{ inputs.runner }} # No need for GPU runner
      parallelism: ${{ inputs.parallelism }}
      post_summary: false # Will post consolidated summary instead

  eks-karpenter:
    name: Kubernetes
    uses: ./.github/workflows/test_k8s.yml
    if: ${{ inputs.kubernetes }}
    secrets: inherit
    concurrency: test-k8s-karpenter # Since the cluster is reused
    with:
      ref: ${{ inputs.ref }}
      debug: ${{ inputs.debug }}
      platform: EKS-Karpenter
      large: ${{ inputs.large }}
      runner: ${{ inputs.runner }}
      runner_gpu: ${{ inputs.runner }} # No need for GPU runner
      parallelism: ${{ inputs.parallelism }}
      post_summary: false # Will post consolidated summary instead

  gke:
    name: Kubernetes
    uses: ./.github/workflows/test_k8s.yml
    if: ${{ inputs.kubernetes }}
    secrets: inherit
    concurrency: test-k8s-gke # Since the cluster is reused
    with:
      ref: ${{ inputs.ref }}
      debug: ${{ inputs.debug }}
      platform: GKE
      large: ${{ inputs.large }}
      runner: ${{ inputs.runner }}
      runner_gpu: ${{ inputs.runner }} # No need for GPU runner
      parallelism: ${{ inputs.parallelism }}
      post_summary: false # Will post consolidated summary instead

  nebius:
    name: Kubernetes
    uses: ./.github/workflows/test_k8s.yml
    if: ${{ inputs.kubernetes && inputs.large }} # Only run Nebius when large=true
    secrets: inherit
    concurrency: test-k8s-nebius # Since the cluster is reused
    with:
      ref: ${{ inputs.ref }}
      debug: ${{ inputs.debug }}
      platform: Nebius
      large: ${{ inputs.large }}
      runner: ${{ inputs.runner }}
      runner_gpu: ${{ inputs.runner }} # No need for GPU runner
      parallelism: ${{ inputs.parallelism }}
      post_summary: false # Will post consolidated summary instead

  post-summary:
    name: Post Summary
    if: always()
    needs: [basic, plugin, streamer, gpu, k3s, eks, gke, nebius]
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        arch:
          - amd64
          - arm64
      max-parallel: 1
    steps:
      - uses: runs-on/action@v1
      - uses: actions/checkout@v4
        with:
          repository: cedana/cedana # required for workflows reusing this workflow
          ref: ${{ inputs.ref }}
          fetch-depth: 0
          fetch-tags: true

      - name: Download report
        id: download-report
        uses: actions/download-artifact@v4
        with:
          pattern: test-report-${{ matrix.arch }}*
          path: report

      - name: Post report
        uses: ctrf-io/github-test-reporter@v1
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        with:
          report-path: report/**/*.json
          github-report: true
          failed-folded-report: true
          flaky-report: true
          summary: true
          pull-request: true
          title: ${{ matrix.arch }}
          update-comment: true
          overwrite-comment: true
          comment-tag: test-report-${{ matrix.arch }}
          group-by: "suite"
          always-group-by: true
          upload-artifact: true
          artifact-name: ctrf-report-${{ matrix.arch }}

      - name: Setup node
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: Generate AI summary of failures
        id: ai-summary
        if: ${{ inputs.post_summary_slack != '' }}
        continue-on-error: true
        env:
          GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
        run: |
          # Check if there are any failures
          FAILED=$(find report -name "*.json" -exec jq -r '.results.summary.failed // 0' {} \; | awk '{s+=$1} END {print s}')
          if [ "$FAILED" -gt 0 ]; then
            echo "Found $FAILED failures, generating AI summary..."
            # Flatten all JSON reports into a single directory for merging
            # (ctrf merge doesn't search recursively)
            mkdir -p /tmp/ctrf-reports
            find report -name "*.json" -exec cp {} /tmp/ctrf-reports/ \;
            # Merge all CTRF reports into one
            npx ctrf merge /tmp/ctrf-reports -o merged-report.json -d /tmp --keep-reports
            npx ai-ctrf gemini "/tmp/merged-report.json" --consolidate --model gemini-2.0-flash \
              --additionalPromptContext "Focus on identifying root causes and common patterns across failures. Be concise." \
              > /tmp/ai-summary.txt 2>&1 || true
            if [ -f /tmp/ai-summary.txt ] && [ -s /tmp/ai-summary.txt ]; then
              # Escape for GitHub Actions output
              SUMMARY=$(cat /tmp/ai-summary.txt | head -c 2000)
              echo "summary<<EOFSUM" >> $GITHUB_OUTPUT
              echo "$SUMMARY" >> $GITHUB_OUTPUT
              echo "EOFSUM" >> $GITHUB_OUTPUT
            fi
          else
            echo "No failures, skipping AI summary"
          fi

      - name: Post report to Slack
        if: ${{ inputs.post_summary_slack != '' }}
        env:
          SLACK_WEBHOOK_URL: ${{ inputs.post_summary_slack == 'nightly' && secrets.SLACK_WEBHOOK_URL_TESTS_NIGHTLY || secrets.SLACK_WEBHOOK_URL_TESTS }}
          TITLE: "Test results (${{ matrix.arch }})"
          BUILD_URL: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
          BRANCH: ${{ github.head_ref || github.ref_name }}
          AI_SUMMARY: ${{ steps.ai-summary.outputs.summary }}
          ARCH: ${{ matrix.arch }}
          # Job results to detect failures without reports
          JOB_RESULTS: ${{ toJSON(needs) }}
        run: |
          node - <<'EOF'
          const fs = require('fs');
          const path = require('path');
          const https = require('https');
          const http = require('http');

          // Find all CTRF JSON files
          function findFiles(dir, pattern) {
            let results = [];
            for (const file of fs.readdirSync(dir, { withFileTypes: true })) {
              const fullPath = path.join(dir, file.name);
              if (file.isDirectory()) {
                results = results.concat(findFiles(fullPath, pattern));
              } else if (file.name.endsWith('.json')) {
                results.push(fullPath);
              }
            }
            return results;
          }

          const files = findFiles('report', '.json');
          const groups = {};
          let totalPassed = 0, totalFailed = 0, totalSkipped = 0, totalTests = 0;

          // Parse each report and group by reportName
          for (const file of files) {
            try {
              const data = JSON.parse(fs.readFileSync(file, 'utf8'));
              const reportName = data.results?.environment?.reportName || data.reportName || path.basename(file, '.json');
              const summary = data.results?.summary || {};

              if (!groups[reportName]) {
                groups[reportName] = { passed: 0, failed: 0, skipped: 0, tests: 0 };
              }
              groups[reportName].passed += summary.passed || 0;
              groups[reportName].failed += summary.failed || 0;
              groups[reportName].skipped += summary.skipped || 0;
              groups[reportName].tests += summary.tests || 0;

              totalPassed += summary.passed || 0;
              totalFailed += summary.failed || 0;
              totalSkipped += summary.skipped || 0;
              totalTests += summary.tests || 0;
            } catch (e) {
              console.error(`Error parsing ${file}:`, e.message);
            }
          }

          const statusEmoji = totalFailed > 0 ? ':x:' : ':white_check_mark:';
          const title = process.env.TITLE || 'Test Results';

          // Build group lines
          const groupLines = Object.entries(groups)
            .sort(([a], [b]) => a.localeCompare(b))
            .map(([name, s]) => {
              const icon = s.failed > 0 ? ':x:' : ':white_check_mark:';
              let line = `${icon} *${name}*: ${s.passed}/${s.tests} passed`;
              if (s.failed > 0) line += ` (${s.failed} failed)`;
              if (s.skipped > 0) line += ` (${s.skipped} skipped)`;
              return line;
            })
            .join('\n');

          // Check for jobs that failed without producing reports
          let crashedJobs = [];
          const arch = process.env.ARCH || 'unknown';
          // Map job IDs to display names and patterns that should appear in report names
          const jobConfig = {
            'basic': { displayName: 'Basic', pattern: 'basic' },
            'plugin': { displayName: null, pattern: null }, // plugin has many sub-reports, skip crash detection
            'streamer': { displayName: 'Streamer (CPU)', pattern: 'streamer' },
            'gpu': { displayName: 'CUDA', pattern: 'cuda' },
            'k3s': { displayName: 'Kubernetes (K3s, CPU)', pattern: 'k3s' },
            'eks': { displayName: 'Kubernetes (EKS, CPU)', pattern: 'eks' },
            'gke': { displayName: 'Kubernetes (GKE, CPU)', pattern: 'gke' },
            'nebius': { displayName: 'Kubernetes (Nebius, GPU)', pattern: 'nebius' },
          };
          try {
            const jobResults = JSON.parse(process.env.JOB_RESULTS || '{}');
            for (const [job, data] of Object.entries(jobResults)) {
              if (data.result === 'failure') {
                const config = jobConfig[job];
                if (!config || config.pattern === null) continue; // Skip jobs we can't reliably detect
                // Check if we have any report for this job
                const hasReport = Object.keys(groups).some(name =>
                  name.toLowerCase().includes(config.pattern || job.toLowerCase())
                );
                if (!hasReport) {
                  crashedJobs.push({ id: job, displayName: config.displayName });
                }
              }
            }
          } catch (e) {
            console.error('Error parsing job results:', e.message);
          }

          // Adjust status if there are crashed jobs
          const hasCrashedJobs = crashedJobs.length > 0;
          const finalStatusEmoji = (totalFailed > 0 || hasCrashedJobs) ? ':x:' : ':white_check_mark:';

          const blocks = [
            { type: 'header', text: { type: 'plain_text', text: title, emoji: true } },
            { type: 'section', text: { type: 'mrkdwn', text: `${finalStatusEmoji} *${totalPassed}* passed  |  :x: *${totalFailed}* failed  |  :fast_forward: *${totalSkipped}* skipped` } },
            { type: 'divider' },
            { type: 'section', text: { type: 'mrkdwn', text: groupLines || 'No test results found' } },
          ];

          // Add crashed jobs section if any
          if (hasCrashedJobs) {
            const crashedLines = crashedJobs.map(j => `:boom: *${j.displayName} (${arch})*: crashed before tests ran`).join('\n');
            blocks.push({ type: 'section', text: { type: 'mrkdwn', text: crashedLines } });
          }

          // Add AI summary if available and there were failures
          const aiSummary = process.env.AI_SUMMARY;
          if (aiSummary && (totalFailed > 0 || hasCrashedJobs)) {
            blocks.push({ type: 'divider' });
            blocks.push({ type: 'section', text: { type: 'mrkdwn', text: `:robot_face: *AI Analysis:*\n${aiSummary}` } });
          }

          blocks.push({ type: 'context', elements: [{ type: 'mrkdwn', text: `<${process.env.BUILD_URL}|View Run> | Branch: \`${process.env.BRANCH}\`` }] });

          const payload = { blocks };

          // Post to Slack
          const webhookUrl = new URL(process.env.SLACK_WEBHOOK_URL);
          const client = webhookUrl.protocol === 'https:' ? https : http;
          const req = client.request(webhookUrl, { method: 'POST', headers: { 'Content-Type': 'application/json' } }, (res) => {
            console.log(`Slack response: ${res.statusCode}`);
          });
          req.write(JSON.stringify(payload));
          req.end();
          EOF
