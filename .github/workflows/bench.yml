name: Bench

permissions:
  contents: "read"
  packages: "read"
  id-token: "write"
  pull-requests: "write"

on:
  workflow_call:
    inputs:
      debug:
        type: boolean
        description: "Run benchmark with debugging enabled"
        required: false
        default: false
      runtimes:
        type: string
        description: "List of comma-separated runtimes to run benchmarks for"
        required: true
        default: cedana
      samples:
        type: string
        description: "Number of samples to run for each metric"
        required: false
        default: 3
      push_results:
        type: boolean
        description: "Push benchmark results to storage"
        required: false
        default: false
      results_dataset:
        type: string
        description: "BigQuery dataset to push results to"
        required: false
        default: "cedana_alpha"
      comparison_runtime:
        type: boolean
        description: "Plot comparison with other runtimes"
        required: false
        default: false
      comparison_previous:
        type: boolean
        description: "Plot comparison with previous result"
        required: false
        default: false
      post_summary_pr:
        type: boolean
        description: "Post benchmark summary to PR"
        required: false
        default: false
      post_summary_slack:
        type: string
        description: "Webhook URL for posting summary to Slack"
        required: false
        default: ""
      runner:
        type: string
        description: "Runner machine for benchmark"
        required: true
        default: "8cpu-32g-1xL4"

env:
  CLOUDSMITH_ENTITLEMENT_TOKEN: ${{ secrets.CLOUDSMITH_ENTITLEMENT_TOKEN }}
  HF_TOKEN: ${{ secrets.HF_TOKEN }}
  CEDANA_URL: ${{ vars.CEDANA_URL }}
  CEDANA_AUTH_TOKEN: ${{ secrets.CEDANA_AUTH_TOKEN }}
  SAMPLES: ${{ inputs.samples }}
  RETRIES: 2

jobs:
  init:
    name: Initialize
    runs-on: ubuntu-latest
    container:
      image: cedana/cedana-bench:slim
      credentials:
        username: ${{ vars.DOCKER_USERNAME }}
        password: ${{ secrets.DOCKER_TOKEN }}
    outputs:
      runtimes_all: ${{ steps.list-runtimes.outputs.runtimes_all }}
      runtimes: ${{ steps.list-runtimes.outputs.runtimes }}
      matrix: ${{ steps.prepare-matrix.outputs.matrix }}
    defaults:
      run:
        working-directory: /src
    steps:
      - name: List runtimes
        id: list-runtimes
        run: |
          runtimes_all=$(jq -c '[.runtimes.list | to_entries[] | .key]' bench.json)
          echo "runtimes_all=$runtimes_all" >> $GITHUB_OUTPUT

          runtimes="[]"
          for runtime in $(echo "${{ inputs.runtimes }}" | tr ', ' ' '); do
            if jq -e ".runtimes.list[\"$runtime\"]" bench.json > /dev/null; then
              runtimes=$(echo "$runtimes" | jq --arg runtime "$runtime" '. + [$runtime]')
            else
              echo "Error: Runtime '$runtime' not found in bench.json" >&2
              exit 1
            fi
          done
          echo "runtimes=$runtimes" >> $GITHUB_OUTPUT

      - name: Prepare matrix
        id: prepare-matrix
        shell: bash
        run: |
          set -euo pipefail
          wanted_runtimes=($(echo "${{ inputs.runtimes }}" | tr ', ' ' '))
          in_runtimes() {
              local r="$1"
              for w in "${wanted_runtimes[@]}"; do
                  [[ "$w" == "$r" ]] && return 0
              done
              return 1
          }
          jq -c '.metrics.list | to_entries[] | select(.value.disabled != true)' bench.json | while read -r entry; do
              metric=$(jq -r '.key' <<< "$entry")
              has_runner=$(jq -r '.value | has("runners")' <<< "$entry")
              if [[ "$has_runner" == true ]]; then
                  jq -r '.value.runners | to_entries[] | "\(.key) \(.value)"' <<< "$entry" | while read -r runtime runner; do
                      if ! in_runtimes "$runtime"; then
                          continue
                      fi
                      jq -r '.value.workloads[]' <<< "$entry" | while read -r workload; do
                          if [[ -f "runners/$runtime/$runner" ]]; then
                              echo "{\"runtime\": \"$runtime\", \"metric\": \"$metric\", \"workload\": \"$workload\"}"
                          fi
                      done
                  done
              fi
          done | jq -s '.' > matrix.json
          matrix=$(jq -c '.' matrix.json)
          echo "matrix=$matrix" >> $GITHUB_OUTPUT

  run:
    name: Run
    needs: init
    runs-on: runs-on=${{github.run_id}}/runner=${{ inputs.runner }}-amd64-cuda-12-4/tag=${{ matrix.runtime }}-${{ matrix.metric }}-${{ matrix.workload }}/extras=s3-cache
    container:
      image: cedana/cedana-bench:cuda
      credentials:
        username: ${{ vars.DOCKER_USERNAME }}
        password: ${{ secrets.DOCKER_TOKEN }}
      options: --privileged --ipc=host --gpus all
    strategy:
      fail-fast: false
      matrix:
        include: ${{ fromJson(needs.init.outputs.matrix) }}
    defaults:
      run:
        working-directory: /src
    steps:
      - uses: runs-on/action@v1

      - name: Download GPU binaries
        uses: actions/download-artifact@v4
        id: download-binaries-gpu
        with:
          name: gpu-amd64

      - name: Download Cedana binary
        uses: actions/download-artifact@v4
        id: download-binaries-cedana
        with:
          name: cedana-amd64

      - name: Download Cedana plugins
        uses: actions/download-artifact@v4
        id: download-binaries-plugins
        with:
          name: plugins-amd64

      - name: Download CRIU binary
        uses: actions/download-artifact@v4
        id: download-binaries-criu
        with:
          name: criu-amd64

      - name: Configure
        env:
          PATH_BINARIES_GPU: ${{ steps.download-binaries-gpu.outputs.download-path }}
          PATH_BINARIES_CEDANA: ${{ steps.download-binaries-cedana.outputs.download-path }}
          PATH_BINARIES_PLUGINS: ${{ steps.download-binaries-plugins.outputs.download-path }}
          PATH_BINARIES_CRIU: ${{ steps.download-binaries-criu.outputs.download-path }}
          COLOR_PALETTE: ${{ vars.BENCH_PALETTE_BRANDED }}
        run: |
          cp $PATH_BINARIES_GPU/* bin
          cp $PATH_BINARIES_CEDANA/* bin
          cp $PATH_BINARIES_PLUGINS/* bin
          cp $PATH_BINARIES_CRIU/* bin
          chmod +x $PATH_BINARIES_GPU/*
          chmod +x $PATH_BINARIES_CEDANA/*
          chmod +x $PATH_BINARIES_CRIU/*
          jq '.runtimes.list."cedana".source = "local"' bench.json > temp.json
          mv temp.json bench.json
          jq 'del(.runtimes.list."cedana".tag)' bench.json > temp.json
          mv temp.json bench.json
          jq '.crtools.list."cedana".source = "local"' bench.json > temp.json
          mv temp.json bench.json
          jq 'del(.crtools.list."cedana".tag)' bench.json > temp.json
          mv temp.json bench.json
          jq '.plots.color_palette = "'$COLOR_PALETTE'"' bench.json > temp.json
          mv temp.json bench.json

      - name: Setup debugging session
        uses: mxschmitt/action-tmate@v3
        if: inputs.debug
        with:
          limit-access-to-actor: true

      - name: Run
        env:
          RUNTIME: ${{ matrix.runtime }}
          METRIC: ${{ matrix.metric }}
          WORKLOAD: ${{ matrix.workload }}
        run: |
          ./bench run $RUNTIME -m $METRIC -w $WORKLOAD -n $SAMPLES -r $RETRIES --save

      - name: Upload logs
        if: always()
        id: upload-logs
        uses: actions/upload-artifact@v4
        with:
          name: bench-logs-${{ matrix.runtime }}-${{ matrix.metric }}-${{ matrix.workload }}
          path: |
            /src/*.log
            /tmp/*.log

      - name: Upload results
        if: always()
        id: upload-results
        uses: actions/upload-artifact@v4
        with:
          name: bench-results-${{ matrix.runtime }}-${{ matrix.metric }}
          path: |
            /src/results

  post-summary:
    name: Post Summary
    if: ${{ !cancelled() }}
    needs: [init, run]
    runs-on: ubuntu-latest
    container:
      image: cedana/cedana-bench:slim
      credentials:
        username: ${{ vars.DOCKER_USERNAME }}
        password: ${{ secrets.DOCKER_TOKEN }}
    strategy:
      fail-fast: false
      matrix:
        runtime: ${{ fromJson(needs.init.outputs.runtimes) }}
    defaults:
      run:
        working-directory: /src
    steps:
      - name: Setup debugging session
        uses: mxschmitt/action-tmate@v3
        if: inputs.debug
        with:
          limit-access-to-actor: true

      - name: Download results
        uses: actions/download-artifact@v4
        id: download-results
        with:
          pattern: bench-results-${{ matrix.runtime }}-*
          merge-multiple: true
          path: /src/results

      - id: auth
        name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v1
        env:
          PROJECT_ID: ${{ vars.GCLOUD_BENCHMARK_PROJECT_ID }}
          WORKLOAD_IDENTITY_PROVIDER: ${{ secrets.GCLOUD_WORKLOAD_IDENTITY_PROVIDER }}
          SERVICE_ACCOUNT: ${{ vars.GCLOUD_SERVICE_ACCOUNT }}
        with:
          project_id: ${{ env.PROJECT_ID }}
          workload_identity_provider: ${{ env.WORKLOAD_IDENTITY_PROVIDER }}
          service_account: ${{ env.SERVICE_ACCOUNT }}

      - name: Push results
        if: inputs.push_results
        env:
          GCLOUD_PROJECT: ${{ vars.GCLOUD_BENCHMARK_PROJECT_ID }}
          BIGQUERY_RESULTS_DATASET: ${{ inputs.results_dataset }}
        run: ./bench results push

      - name: Pull last results
        env:
          GCLOUD_PROJECT: ${{ vars.GCLOUD_BENCHMARK_PROJECT_ID }}
          BIGQUERY_RESULTS_DATASET: ${{ inputs.results_dataset }}
        run: |
          runtime_args=""
          for runtime in $(echo '${{ needs.init.outputs.runtimes_all }}' | jq -r '.[]'); do
            runtime_args="$runtime_args --runtime $runtime:2"
          done
          ./bench results pull $runtime_args -f

      - name: Plot comparison (runtime)
        if: inputs.comparison_runtime
        env:
          COLOR_PALETTE: ${{ vars.BENCH_PALETTE_COMPARISON_RUNTIME }}
          FLAGS: ${{ vars.BENCH_PLOT_FLAGS }}
          RUNTIME: ${{ matrix.runtime }}
        run: |
          runtime_args=""
          for runtime in $(echo '${{ needs.init.outputs.runtimes_all }}' | jq -r '.[]'); do
            if [ "$runtime" != $RUNTIME ]; then
              runtime_args="$runtime_args --runtime $runtime"
            fi
          done
          ./bench plot $runtime_args --runtime $RUNTIME --save $FLAGS --palette $COLOR_PALETTE

      - name: Upload plots (runtime comparison)
        if: inputs.comparison_runtime
        id: upload-plots-runtime
        uses: google-github-actions/upload-cloud-storage@v2
        with:
          predefinedAcl: publicRead
          project_id: ${{ steps.auth.outputs.project_id }}
          path: /src/results
          destination: ${{ github.repository }}/${{ github.head_ref || github.ref_name }}/${{ github.run_id }}/runtime-comparison
          glob: "**/*.png"

      - name: Generate summary (runtime comparison)
        if: inputs.comparison_runtime
        id: summary-runtime
        env:
          RESULTS_BASE_URL: https://storage.googleapis.com/${{ github.repository }}/${{ github.head_ref || github.ref_name }}/${{ github.run_id }}/runtime-comparison/results
          RESULTS_TITLE: ${{ github.repository }}
          RESULTS_DESCRIPTION: "**${{ github.head_ref || github.ref_name }}** (right) comparison with other runtimes (left)"
          RELEASE_NOTES_URL: https://github.com/${{ github.repository }}/releases/${{ github.head_ref || github.ref_name }}
        run: |
          rm -f summary.md
          utils/results-summary > $GITHUB_STEP_SUMMARY
          utils/results-summary > summary.md
          echo ::set-output name=slack_summary::$(utils/results-summary-slack)

      - name: Post summary to Slack (runtime comparison)
        if: ${{ inputs.post_summary_slack != '' && inputs.comparison_runtime }}
        id: slack-runtime
        uses: slackapi/slack-github-action@v1.26.0
        env:
          SLACK_WEBHOOK_URL: ${{ inputs.post_summary_slack == 'nightly' && secrets.SLACK_WEBHOOK_URL_PERFORMANCE_NIGHTLY || secrets.SLACK_WEBHOOK_URL_PERFORMANCE }}
          SLACK_WEBHOOK_TYPE: INCOMING_WEBHOOK
        with:
          payload: |
            ${{ steps.summary-runtime.outputs.slack_summary }}

      - name: Post summary to PR (runtime comparison)
        if: inputs.post_summary_pr && inputs.comparison_runtime
        uses: thollander/actions-comment-pull-request@v2
        with:
          filePath: /src/summary.md
          comment_tag: comparison_runtime

      - name: Plot comparison (previous)
        if: inputs.comparison_previous
        env:
          COLOR_PALETTE: ${{ vars.BENCH_PALETTE_COMPARISON_PREVIOUS }}
          FLAGS: ${{ vars.BENCH_PLOT_FLAGS }}
          RUNTIME: ${{ matrix.runtime }}
        run: |
          rm -rf results/*.png
          ./bench plot --runtime $RUNTIME:2 --save $FLAGS --palette $COLOR_PALETTE

      - name: Upload plots (previous comparison)
        if: inputs.comparison_previous
        id: upload-plots-previous
        uses: google-github-actions/upload-cloud-storage@v2
        with:
          predefinedAcl: publicRead
          project_id: ${{ steps.auth.outputs.project_id }}
          path: /src/results
          destination: ${{ github.repository }}/${{ github.head_ref || github.ref_name }}/${{ github.run_id }}/previous-comparison
          glob: "**/*.png"

      - name: Generate summary (previous comparison)
        if: inputs.comparison_previous
        id: summary-previous
        env:
          RESULTS_BASE_URL: https://storage.googleapis.com/${{ github.repository }}/${{ github.head_ref || github.ref_name }}/${{ github.run_id }}/previous-comparison/results
          RESULTS_TITLE: ${{ github.repository }}
          RESULTS_DESCRIPTION: "**${{ github.head_ref || github.ref_name }}** (right) comparison with previous result (left)"
          RELEASE_NOTES_URL: https://github.com/${{ github.repository }}/releases/${{ github.head_ref || github.ref_name }}
        run: |
          rm -f summary.md
          utils/results-summary > $GITHUB_STEP_SUMMARY
          utils/results-summary > summary.md
          echo ::set-output name=slack_summary::$(utils/results-summary-slack)

      - name: Post summary to PR (previous comparison)
        if: inputs.post_summary_pr && inputs.comparison_previous
        uses: thollander/actions-comment-pull-request@v2
        with:
          filePath: /src/summary.md
          comment_tag: comparison_previous

      - name: Post summary to Slack (previous comparison)
        if: ${{ inputs.post_summary_slack != '' && inputs.comparison_previous }}
        id: slack-previous
        uses: slackapi/slack-github-action@v1.26.0
        env:
          SLACK_WEBHOOK_URL: ${{ inputs.post_summary_slack == 'nightly' && secrets.SLACK_WEBHOOK_URL_PERFORMANCE_NIGHTLY || secrets.SLACK_WEBHOOK_URL_PERFORMANCE }}
          SLACK_WEBHOOK_TYPE: INCOMING_WEBHOOK
        with:
          payload: |
            ${{ steps.summary-previous.outputs.slack_summary }}

      - name: Plot
        if: ${{ ! inputs.comparison_runtime && !inputs.comparison_previous }}
        env:
          COLOR_PALETTE: ${{ vars.BENCH_PALETTE_BRANDED }}
          FLAGS: ${{ vars.BENCH_PLOT_FLAGS }}
          RUNTIME: ${{ matrix.runtime }}
        run: ./bench plot --runtime $RUNTIME --save $FLAGS --palette $COLOR_PALETTE

      - name: Upload plots
        if: ${{ ! inputs.comparison_runtime && !inputs.comparison_previous }}
        id: upload-plots
        uses: google-github-actions/upload-cloud-storage@v2
        with:
          predefinedAcl: publicRead
          project_id: ${{ steps.auth.outputs.project_id }}
          path: /src/results
          destination: ${{ github.repository }}/${{ github.head_ref || github.ref_name }}/${{ github.run_id }}
          glob: "**/*.png"

      - name: Generate summary
        if: ${{ ! inputs.comparison_runtime && !inputs.comparison_previous }}
        env:
          RESULTS_BASE_URL: https://storage.googleapis.com/${{ github.repository }}/${{ github.head_ref || github.ref_name }}/${{ github.run_id }}/results
          RESULTS_TITLE: ${{ github.repository }}
          RESULTS_DESCRIPTION: "**${{ github.head_ref || github.ref_name }}** (${{ matrix.runtime }}) results"
          RELEASE_NOTES_URL: https://github.com/${{ github.repository }}/releases/${{ github.head_ref || github.ref_name }}
        run: |
          rm -f summary.md
          utils/results-summary > $GITHUB_STEP_SUMMARY
          utils/results-summary > summary.md
